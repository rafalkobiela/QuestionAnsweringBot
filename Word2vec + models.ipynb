{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Janusze AI\n",
    "* Rafał Kobiela\n",
    "* Mateusz Krubiński\n",
    "* Piotr Bródka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot odpowiadający na pytania użytkownika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafal/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(file='glove.6B.300d'):\n",
    "    output_file = config.config['embeddings_path']['glove']\n",
    "    embeddings_index = {}\n",
    "    wrong = []\n",
    "    repeated = []\n",
    "    if(os.path.isfile(output_file)):\n",
    "        print('Loading serialized embeddings...')\n",
    "        embeddings_index = pkl.load(open(output_file, \"rb\"))\n",
    "    else:\n",
    "        print('Loading raw embeddings from file...')\n",
    "        f = open(file, encoding = 'utf8')\n",
    "        for line in tqdm(f):\n",
    "            values = line.split()\n",
    "            if len(values) == 301:\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "                if word not in embeddings_index.keys():\n",
    "                    embeddings_index[word] = coefs\n",
    "                else:\n",
    "                    repeated.append(values)\n",
    "            else:\n",
    "                wrong.append(values)\n",
    "        f.close()\n",
    "        pkl.dump(embeddings_index, open(output_file, \"wb\"))\n",
    "    print('Found %s word vectors. %s wrong, %s repeated' % (len(embeddings_index), len(wrong), len(repeated)))\n",
    "    return embeddings_index, wrong, repeated\n",
    "\n",
    "def load_w2v_embeddings():\n",
    "    w2vModel = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "    return w2vModel \n",
    "\n",
    "def init(embeddings_type = 'glove'):\n",
    "    if embeddings_type == 'glove':\n",
    "        global embeddings_index_global\n",
    "        embeddings_index_global, wrong, repeated = load_glove_embeddings()\n",
    "    elif embeddings_type == 'w2v':    \n",
    "        global w2vModel\n",
    "        w2vModel = load_w2v_embeddings()\n",
    "    else:\n",
    "        raise NameError('Invalid embedding type %s' % embeddings_type)     \n",
    "        \n",
    "def get_embeddings(embeddings_type = 'glove'):\n",
    "    if embeddings_type == 'glove':\n",
    "        global embeddings_index_global\n",
    "        try:\n",
    "            return embeddings_index_global\n",
    "        except NameError:\n",
    "            init(embeddings_type)\n",
    "            return embeddings_index_global\n",
    "    elif embeddings_type == 'w2v':\n",
    "        global w2vModel\n",
    "        try:\n",
    "            return w2vModel\n",
    "        except NameError:\n",
    "            init(embeddings_type)\n",
    "            return w2vModel\n",
    "    else:\n",
    "        raise NameError('Invalid embedding type %s' % embeddings_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sent2Vec():\n",
    "    def __init__(self, embeddings_index=None):\n",
    "        self.embeddings_index = None\n",
    "        if(embeddings_index != None):\n",
    "            self.embeddings_index = embeddings_index\n",
    "        self.unknown_words = []\n",
    "    def fit_transform(self, texts):\n",
    "        return self.transform(texts);\n",
    "    def _transform(self, text):\n",
    "        M = []\n",
    "        words = word_tokenize(text)\n",
    "        for w in words:\n",
    "            try:\n",
    "                M.append(self.embeddings_index[w])\n",
    "            except KeyError:\n",
    "                self.unknown_words.append(w)\n",
    "                #print('Word not found: ', w)\n",
    "                continue\n",
    "        M = np.array(M, dtype = np.float64)\n",
    "        v = M.sum(axis=0)\n",
    "        if type(v) != np.ndarray:\n",
    "            return np.zeros(300)\n",
    "        return v / np.sqrt((v ** 2).sum())\n",
    "    def transform(self, texts):\n",
    "        print(\"Sent2Vec started..\")\n",
    "        if self.embeddings_index == None:\n",
    "            print(\"Lazy loading embeddings...\")\n",
    "            self.embeddings_index = get_embeddings()\n",
    "        \n",
    "        res = [self._transform(x) for x in tqdm(texts)]\n",
    "        #self.embeddings_index = None\n",
    "        return res\n",
    "    def fit(self, texts):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedSizeArray():\n",
    "    def __init__(self, dimensions, timesteps, word2vec_mod = None):\n",
    "        self.dim = dimensions\n",
    "        self.steps = timesteps\n",
    "        self.w2v = word2vec_mod\n",
    "    def fit_transform(self, texts):\n",
    "        return self.transform(texts)\n",
    "    \n",
    "    def fit(self, texts):\n",
    "        return None\n",
    "    \n",
    "    def _transform(self, article):\n",
    "        tokens = CountVectorizer().build_tokenizer()(article) \n",
    "        doc_vectors_gen = (self.w2v[a].tolist() for a in tokens if a in self.w2v.vocab)\n",
    "        doc_vectors = [a for (i, a) in enumerate(doc_vectors_gen) if i <self.steps]\n",
    "        \n",
    "        while len(doc_vectors) < self.steps:\n",
    "            doc_vectors.append([0])\n",
    "    \n",
    "        pad_vectors = pad_sequences(doc_vectors,padding='post',dtype='float32', maxlen=self.dim, value=0.)\n",
    "        return pad_vectors\n",
    "    \n",
    "    def transform(self, texts):\n",
    "        #print(\"FixedSizeArray of embeddings started..\")\n",
    "        if self.w2v == None:\n",
    "            #print(\"Lazy loading embeddings...\")\n",
    "            self.w2v = get_embeddings('w2v')\n",
    "        \n",
    "        res = self._transform(texts.lower())\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsa = FixedSizeArray(300,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('output.csv', sep = '|').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1212/1212 [00:17<00:00, 70.09it/s]\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame(df.iloc[0,:]).transpose()\n",
    "for i in tqdm(list(set(list(df['Question'].values)))):\n",
    "    tmp = df[df['Question'] == i]\n",
    "    df_final = df_final.append(tmp.iloc[0,:])\n",
    "    if tmp.shape[0] >= 5:\n",
    "        df_final = df_final.append(tmp.iloc[np.random.randint(tmp.shape[0]),:])\n",
    "        df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "        df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]\n",
    "        df_final = df_final.append(tmp.iloc[np.random.randint(tmp.shape[0]),:])\n",
    "        df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "        df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]\n",
    "        df_final = df_final.append(tmp.iloc[np.random.randint(tmp.shape[0]),:])\n",
    "        df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "        df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]\n",
    "        df_final = df_final.append(tmp.iloc[np.random.randint(tmp.shape[0]),:])\n",
    "        df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "        df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]\n",
    "        df_final = df_final.append(tmp.iloc[np.random.randint(tmp.shape[0]),:])\n",
    "        df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "        df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]\n",
    "        \n",
    "        df_final = df_final.append(df.iloc[np.random.randint(df.shape[0]),:])\n",
    "        df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "        df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]\n",
    "        \n",
    "    else:\n",
    "        for j in range(tmp.shape[0]):\n",
    "            df_final = df_final.append(tmp.iloc[j,:])\n",
    "            df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "            df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]\n",
    "        for j in range(6 - tmp.shape[0]):\n",
    "            df_final = df_final.append(df.iloc[np.random.randint(df.shape[0]),:])\n",
    "            df_final.iloc[df_final.shape[0] - 1, 1] = tmp.iloc[0,1]\n",
    "            df_final.iloc[df_final.shape[0] - 1, 0] = tmp.iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_final.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Pos_answer</th>\n",
       "      <th>Neg_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9599</th>\n",
       "      <td>when is it memorial day</td>\n",
       "      <td>Memorial Day is a United States federal holida...</td>\n",
       "      <td>Memorial Day is a day of remembering the men a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9602</th>\n",
       "      <td>when is it memorial day</td>\n",
       "      <td>Memorial Day is a United States federal holida...</td>\n",
       "      <td>It typically marks the start of the summer vac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>when is it memorial day</td>\n",
       "      <td>Memorial Day is a United States federal holida...</td>\n",
       "      <td>By the 20th century Memorial Day had been exte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9611</th>\n",
       "      <td>when is it memorial day</td>\n",
       "      <td>Memorial Day is a United States federal holida...</td>\n",
       "      <td>It is believed that this practice began before...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9612</th>\n",
       "      <td>when is it memorial day</td>\n",
       "      <td>Memorial Day is a United States federal holida...</td>\n",
       "      <td>Memorial Day is not to be confused with Vetera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9602</th>\n",
       "      <td>when is it memorial day</td>\n",
       "      <td>Memorial Day is a United States federal holida...</td>\n",
       "      <td>It typically marks the start of the summer vac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>when is it memorial day</td>\n",
       "      <td>Memorial Day is a United States federal holida...</td>\n",
       "      <td>Artist's impression of the moon during the Lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10186</th>\n",
       "      <td>when was washington elected president</td>\n",
       "      <td>George Washington ( – , 1799) was the first Pr...</td>\n",
       "      <td>He presided over the convention that drafted t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10193</th>\n",
       "      <td>when was washington elected president</td>\n",
       "      <td>George Washington ( – , 1799) was the first Pr...</td>\n",
       "      <td>After both his father and older brother died w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>when was washington elected president</td>\n",
       "      <td>George Washington ( – , 1799) was the first Pr...</td>\n",
       "      <td>Washington had a vision of a great and powerfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10192</th>\n",
       "      <td>when was washington elected president</td>\n",
       "      <td>George Washington ( – , 1799) was the first Pr...</td>\n",
       "      <td>Washington was born into the provincial gentry...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10193</th>\n",
       "      <td>when was washington elected president</td>\n",
       "      <td>George Washington ( – , 1799) was the first Pr...</td>\n",
       "      <td>After both his father and older brother died w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>when was washington elected president</td>\n",
       "      <td>George Washington ( – , 1799) was the first Pr...</td>\n",
       "      <td>Elected unanimously as the first President of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>when was washington elected president</td>\n",
       "      <td>George Washington ( – , 1799) was the first Pr...</td>\n",
       "      <td>In June 2007, Sampson was married to Laura How...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>how many users do twitter have</td>\n",
       "      <td>The service rapidly gained worldwide popularit...</td>\n",
       "      <td>Twitter is an online social networking service...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>how many users do twitter have</td>\n",
       "      <td>The service rapidly gained worldwide popularit...</td>\n",
       "      <td>Twitter was created in March 2006 by Jack Dors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>how many users do twitter have</td>\n",
       "      <td>The service rapidly gained worldwide popularit...</td>\n",
       "      <td>Since its launch, Twitter has become one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>how many users do twitter have</td>\n",
       "      <td>The service rapidly gained worldwide popularit...</td>\n",
       "      <td>Unregistered users can read tweets, while regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>how many users do twitter have</td>\n",
       "      <td>The service rapidly gained worldwide popularit...</td>\n",
       "      <td>Twitter was created in March 2006 by Jack Dors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>how many users do twitter have</td>\n",
       "      <td>The service rapidly gained worldwide popularit...</td>\n",
       "      <td>Since its launch, Twitter has become one of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>how many users do twitter have</td>\n",
       "      <td>The service rapidly gained worldwide popularit...</td>\n",
       "      <td>At the heart of the conflict was the question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>what part of beef are rouladen cut from?</td>\n",
       "      <td>The cut is usually topside beef or silverside ...</td>\n",
       "      <td>Uncooked Rouladen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>what part of beef are rouladen cut from?</td>\n",
       "      <td>The cut is usually topside beef or silverside ...</td>\n",
       "      <td>The mixture varies from region to region.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>what part of beef are rouladen cut from?</td>\n",
       "      <td>The cut is usually topside beef or silverside ...</td>\n",
       "      <td>Rouladen (or Rinderroulade, singular: roulade)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>what part of beef are rouladen cut from?</td>\n",
       "      <td>The cut is usually topside beef or silverside ...</td>\n",
       "      <td>Beef or veal is used as meat though some food ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7600</th>\n",
       "      <td>what part of beef are rouladen cut from?</td>\n",
       "      <td>The cut is usually topside beef or silverside ...</td>\n",
       "      <td>Uncooked Rouladen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7601</th>\n",
       "      <td>what part of beef are rouladen cut from?</td>\n",
       "      <td>The cut is usually topside beef or silverside ...</td>\n",
       "      <td>Rouladen (or Rinderroulade, singular: roulade)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9442</th>\n",
       "      <td>what part of beef are rouladen cut from?</td>\n",
       "      <td>The cut is usually topside beef or silverside ...</td>\n",
       "      <td>By the end of the war, four major imperial pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8049</th>\n",
       "      <td>what states does interstate 70 travel through</td>\n",
       "      <td>Interstate 70 (I-70) is an Interstate Highway ...</td>\n",
       "      <td>It was the first Interstate Highway project in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8053</th>\n",
       "      <td>what states does interstate 70 travel through</td>\n",
       "      <td>Interstate 70 (I-70) is an Interstate Highway ...</td>\n",
       "      <td>The construction of I-70 in Colorado and Utah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152</th>\n",
       "      <td>when was the tacoma bridge collapse?</td>\n",
       "      <td>The bridge became known for its pitching deck,...</td>\n",
       "      <td>Engineering issues as well as the United State...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>when was the tacoma bridge collapse?</td>\n",
       "      <td>The bridge became known for its pitching deck,...</td>\n",
       "      <td>Social problems, such as long-term unemploymen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2510</th>\n",
       "      <td>how much does united states spend on health care</td>\n",
       "      <td>According to the World Health Organization (WH...</td>\n",
       "      <td>Health care in the United States is provided b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>how much does united states spend on health care</td>\n",
       "      <td>According to the World Health Organization (WH...</td>\n",
       "      <td>Together, such issues place the U.S. at the bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>how much does united states spend on health care</td>\n",
       "      <td>According to the World Health Organization (WH...</td>\n",
       "      <td>60-65% of healthcare provision and spending co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>how much does united states spend on health care</td>\n",
       "      <td>According to the World Health Organization (WH...</td>\n",
       "      <td>The U.S. Census Bureau reported that 49.9 mill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>how much does united states spend on health care</td>\n",
       "      <td>According to the World Health Organization (WH...</td>\n",
       "      <td>Health care facilities are largely owned and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2511</th>\n",
       "      <td>how much does united states spend on health care</td>\n",
       "      <td>According to the World Health Organization (WH...</td>\n",
       "      <td>Health care facilities are largely owned and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10357</th>\n",
       "      <td>how much does united states spend on health care</td>\n",
       "      <td>According to the World Health Organization (WH...</td>\n",
       "      <td>Mark A. Jackson (born April 1, 1965) is an Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5028</th>\n",
       "      <td>what is 9/11 bombings</td>\n",
       "      <td>The September 11 attacks (also referred to as ...</td>\n",
       "      <td>Four passenger airliners were hijacked by 19 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5036</th>\n",
       "      <td>what is 9/11 bombings</td>\n",
       "      <td>The September 11 attacks (also referred to as ...</td>\n",
       "      <td>Al-Qaeda and bin Laden cited U.S. support of I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>what is 9/11 bombings</td>\n",
       "      <td>The September 11 attacks (also referred to as ...</td>\n",
       "      <td>A third plane, American Airlines Flight 77 , w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>what is 9/11 bombings</td>\n",
       "      <td>The September 11 attacks (also referred to as ...</td>\n",
       "      <td>Having evaded capture for years, bin Laden was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5039</th>\n",
       "      <td>what is 9/11 bombings</td>\n",
       "      <td>The September 11 attacks (also referred to as ...</td>\n",
       "      <td>Having evaded capture for years, bin Laden was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5038</th>\n",
       "      <td>what is 9/11 bombings</td>\n",
       "      <td>The September 11 attacks (also referred to as ...</td>\n",
       "      <td>Many countries strengthened their anti-terrori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>what is 9/11 bombings</td>\n",
       "      <td>The September 11 attacks (also referred to as ...</td>\n",
       "      <td>Vitamin A is a group of nutritionally unsatura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>who owns popeyes chicken</td>\n",
       "      <td>Often referred to as Popeyes and sometimes as ...</td>\n",
       "      <td>Popeyes Louisiana Kitchen is a chain of fried ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>who owns popeyes chicken</td>\n",
       "      <td>Often referred to as Popeyes and sometimes as ...</td>\n",
       "      <td>Popeyes Louisiana Kitchen is a chain of fried ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>who owns popeyes chicken</td>\n",
       "      <td>Often referred to as Popeyes and sometimes as ...</td>\n",
       "      <td>According to a company press release dated Jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>who owns popeyes chicken</td>\n",
       "      <td>Often referred to as Popeyes and sometimes as ...</td>\n",
       "      <td>About thirty locations are company-owned, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6539</th>\n",
       "      <td>who owns popeyes chicken</td>\n",
       "      <td>Often referred to as Popeyes and sometimes as ...</td>\n",
       "      <td>It also allows individuals to apply their mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>who owns popeyes chicken</td>\n",
       "      <td>Often referred to as Popeyes and sometimes as ...</td>\n",
       "      <td>RCA Victor acquired his contract in a deal arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>who owns popeyes chicken</td>\n",
       "      <td>Often referred to as Popeyes and sometimes as ...</td>\n",
       "      <td>In the narrative of the Exodus , the Bible tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>what countries are in central america?</td>\n",
       "      <td>Central America consists of seven countries: B...</td>\n",
       "      <td>Central America () is the central geographic r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>what countries are in central america?</td>\n",
       "      <td>Central America consists of seven countries: B...</td>\n",
       "      <td>It is the southernmost, isthmian portion of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>what countries are in central america?</td>\n",
       "      <td>Central America consists of seven countries: B...</td>\n",
       "      <td>It has a density of 77 people per square kilom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>what countries are in central america?</td>\n",
       "      <td>Central America consists of seven countries: B...</td>\n",
       "      <td>Central America is part of the Mesoamerican bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>what countries are in central america?</td>\n",
       "      <td>Central America consists of seven countries: B...</td>\n",
       "      <td>It has a density of 77 people per square kilom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>what countries are in central america?</td>\n",
       "      <td>Central America consists of seven countries: B...</td>\n",
       "      <td>Central America is part of the Mesoamerican bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>what countries are in central america?</td>\n",
       "      <td>Central America consists of seven countries: B...</td>\n",
       "      <td>The Union marshaled the resources and manpower...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8484 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Question  \\\n",
       "9599                            when is it memorial day   \n",
       "9602                            when is it memorial day   \n",
       "9601                            when is it memorial day   \n",
       "9611                            when is it memorial day   \n",
       "9612                            when is it memorial day   \n",
       "9602                            when is it memorial day   \n",
       "4929                            when is it memorial day   \n",
       "10186             when was washington elected president   \n",
       "10193             when was washington elected president   \n",
       "10210             when was washington elected president   \n",
       "10192             when was washington elected president   \n",
       "10193             when was washington elected president   \n",
       "10202             when was washington elected president   \n",
       "210               when was washington elected president   \n",
       "2411                     how many users do twitter have   \n",
       "2412                     how many users do twitter have   \n",
       "2413                     how many users do twitter have   \n",
       "2414                     how many users do twitter have   \n",
       "2412                     how many users do twitter have   \n",
       "2413                     how many users do twitter have   \n",
       "9814                     how many users do twitter have   \n",
       "7600           what part of beef are rouladen cut from?   \n",
       "7608           what part of beef are rouladen cut from?   \n",
       "7601           what part of beef are rouladen cut from?   \n",
       "7603           what part of beef are rouladen cut from?   \n",
       "7600           what part of beef are rouladen cut from?   \n",
       "7601           what part of beef are rouladen cut from?   \n",
       "9442           what part of beef are rouladen cut from?   \n",
       "8049      what states does interstate 70 travel through   \n",
       "8053      what states does interstate 70 travel through   \n",
       "...                                                 ...   \n",
       "10152              when was the tacoma bridge collapse?   \n",
       "1621               when was the tacoma bridge collapse?   \n",
       "2510   how much does united states spend on health care   \n",
       "2516   how much does united states spend on health care   \n",
       "2513   how much does united states spend on health care   \n",
       "2519   how much does united states spend on health care   \n",
       "2511   how much does united states spend on health care   \n",
       "2511   how much does united states spend on health care   \n",
       "10357  how much does united states spend on health care   \n",
       "5028                              what is 9/11 bombings   \n",
       "5036                              what is 9/11 bombings   \n",
       "5031                              what is 9/11 bombings   \n",
       "5039                              what is 9/11 bombings   \n",
       "5039                              what is 9/11 bombings   \n",
       "5038                              what is 9/11 bombings   \n",
       "7167                              what is 9/11 bombings   \n",
       "11998                          who owns popeyes chicken   \n",
       "11998                          who owns popeyes chicken   \n",
       "11999                          who owns popeyes chicken   \n",
       "12000                          who owns popeyes chicken   \n",
       "6539                           who owns popeyes chicken   \n",
       "8674                           who owns popeyes chicken   \n",
       "629                            who owns popeyes chicken   \n",
       "3869             what countries are in central america?   \n",
       "3870             what countries are in central america?   \n",
       "3876             what countries are in central america?   \n",
       "3872             what countries are in central america?   \n",
       "3876             what countries are in central america?   \n",
       "3872             what countries are in central america?   \n",
       "8031             what countries are in central america?   \n",
       "\n",
       "                                              Pos_answer  \\\n",
       "9599   Memorial Day is a United States federal holida...   \n",
       "9602   Memorial Day is a United States federal holida...   \n",
       "9601   Memorial Day is a United States federal holida...   \n",
       "9611   Memorial Day is a United States federal holida...   \n",
       "9612   Memorial Day is a United States federal holida...   \n",
       "9602   Memorial Day is a United States federal holida...   \n",
       "4929   Memorial Day is a United States federal holida...   \n",
       "10186  George Washington ( – , 1799) was the first Pr...   \n",
       "10193  George Washington ( – , 1799) was the first Pr...   \n",
       "10210  George Washington ( – , 1799) was the first Pr...   \n",
       "10192  George Washington ( – , 1799) was the first Pr...   \n",
       "10193  George Washington ( – , 1799) was the first Pr...   \n",
       "10202  George Washington ( – , 1799) was the first Pr...   \n",
       "210    George Washington ( – , 1799) was the first Pr...   \n",
       "2411   The service rapidly gained worldwide popularit...   \n",
       "2412   The service rapidly gained worldwide popularit...   \n",
       "2413   The service rapidly gained worldwide popularit...   \n",
       "2414   The service rapidly gained worldwide popularit...   \n",
       "2412   The service rapidly gained worldwide popularit...   \n",
       "2413   The service rapidly gained worldwide popularit...   \n",
       "9814   The service rapidly gained worldwide popularit...   \n",
       "7600   The cut is usually topside beef or silverside ...   \n",
       "7608   The cut is usually topside beef or silverside ...   \n",
       "7601   The cut is usually topside beef or silverside ...   \n",
       "7603   The cut is usually topside beef or silverside ...   \n",
       "7600   The cut is usually topside beef or silverside ...   \n",
       "7601   The cut is usually topside beef or silverside ...   \n",
       "9442   The cut is usually topside beef or silverside ...   \n",
       "8049   Interstate 70 (I-70) is an Interstate Highway ...   \n",
       "8053   Interstate 70 (I-70) is an Interstate Highway ...   \n",
       "...                                                  ...   \n",
       "10152  The bridge became known for its pitching deck,...   \n",
       "1621   The bridge became known for its pitching deck,...   \n",
       "2510   According to the World Health Organization (WH...   \n",
       "2516   According to the World Health Organization (WH...   \n",
       "2513   According to the World Health Organization (WH...   \n",
       "2519   According to the World Health Organization (WH...   \n",
       "2511   According to the World Health Organization (WH...   \n",
       "2511   According to the World Health Organization (WH...   \n",
       "10357  According to the World Health Organization (WH...   \n",
       "5028   The September 11 attacks (also referred to as ...   \n",
       "5036   The September 11 attacks (also referred to as ...   \n",
       "5031   The September 11 attacks (also referred to as ...   \n",
       "5039   The September 11 attacks (also referred to as ...   \n",
       "5039   The September 11 attacks (also referred to as ...   \n",
       "5038   The September 11 attacks (also referred to as ...   \n",
       "7167   The September 11 attacks (also referred to as ...   \n",
       "11998  Often referred to as Popeyes and sometimes as ...   \n",
       "11998  Often referred to as Popeyes and sometimes as ...   \n",
       "11999  Often referred to as Popeyes and sometimes as ...   \n",
       "12000  Often referred to as Popeyes and sometimes as ...   \n",
       "6539   Often referred to as Popeyes and sometimes as ...   \n",
       "8674   Often referred to as Popeyes and sometimes as ...   \n",
       "629    Often referred to as Popeyes and sometimes as ...   \n",
       "3869   Central America consists of seven countries: B...   \n",
       "3870   Central America consists of seven countries: B...   \n",
       "3876   Central America consists of seven countries: B...   \n",
       "3872   Central America consists of seven countries: B...   \n",
       "3876   Central America consists of seven countries: B...   \n",
       "3872   Central America consists of seven countries: B...   \n",
       "8031   Central America consists of seven countries: B...   \n",
       "\n",
       "                                              Neg_answer  \n",
       "9599   Memorial Day is a day of remembering the men a...  \n",
       "9602   It typically marks the start of the summer vac...  \n",
       "9601   By the 20th century Memorial Day had been exte...  \n",
       "9611   It is believed that this practice began before...  \n",
       "9612   Memorial Day is not to be confused with Vetera...  \n",
       "9602   It typically marks the start of the summer vac...  \n",
       "4929   Artist's impression of the moon during the Lat...  \n",
       "10186  He presided over the convention that drafted t...  \n",
       "10193  After both his father and older brother died w...  \n",
       "10210  Washington had a vision of a great and powerfu...  \n",
       "10192  Washington was born into the provincial gentry...  \n",
       "10193  After both his father and older brother died w...  \n",
       "10202  Elected unanimously as the first President of ...  \n",
       "210    In June 2007, Sampson was married to Laura How...  \n",
       "2411   Twitter is an online social networking service...  \n",
       "2412   Twitter was created in March 2006 by Jack Dors...  \n",
       "2413   Since its launch, Twitter has become one of th...  \n",
       "2414   Unregistered users can read tweets, while regi...  \n",
       "2412   Twitter was created in March 2006 by Jack Dors...  \n",
       "2413   Since its launch, Twitter has become one of th...  \n",
       "9814   At the heart of the conflict was the question ...  \n",
       "7600                                   Uncooked Rouladen  \n",
       "7608           The mixture varies from region to region.  \n",
       "7601   Rouladen (or Rinderroulade, singular: roulade)...  \n",
       "7603   Beef or veal is used as meat though some food ...  \n",
       "7600                                   Uncooked Rouladen  \n",
       "7601   Rouladen (or Rinderroulade, singular: roulade)...  \n",
       "9442   By the end of the war, four major imperial pow...  \n",
       "8049   It was the first Interstate Highway project in...  \n",
       "8053   The construction of I-70 in Colorado and Utah ...  \n",
       "...                                                  ...  \n",
       "10152  Engineering issues as well as the United State...  \n",
       "1621   Social problems, such as long-term unemploymen...  \n",
       "2510   Health care in the United States is provided b...  \n",
       "2516   Together, such issues place the U.S. at the bo...  \n",
       "2513   60-65% of healthcare provision and spending co...  \n",
       "2519   The U.S. Census Bureau reported that 49.9 mill...  \n",
       "2511   Health care facilities are largely owned and o...  \n",
       "2511   Health care facilities are largely owned and o...  \n",
       "10357  Mark A. Jackson (born April 1, 1965) is an Ame...  \n",
       "5028   Four passenger airliners were hijacked by 19 a...  \n",
       "5036   Al-Qaeda and bin Laden cited U.S. support of I...  \n",
       "5031   A third plane, American Airlines Flight 77 , w...  \n",
       "5039   Having evaded capture for years, bin Laden was...  \n",
       "5039   Having evaded capture for years, bin Laden was...  \n",
       "5038   Many countries strengthened their anti-terrori...  \n",
       "7167   Vitamin A is a group of nutritionally unsatura...  \n",
       "11998  Popeyes Louisiana Kitchen is a chain of fried ...  \n",
       "11998  Popeyes Louisiana Kitchen is a chain of fried ...  \n",
       "11999  According to a company press release dated Jun...  \n",
       "12000  About thirty locations are company-owned, the ...  \n",
       "6539   It also allows individuals to apply their mont...  \n",
       "8674   RCA Victor acquired his contract in a deal arr...  \n",
       "629    In the narrative of the Exodus , the Bible tel...  \n",
       "3869   Central America () is the central geographic r...  \n",
       "3870   It is the southernmost, isthmian portion of th...  \n",
       "3876   It has a density of 77 people per square kilom...  \n",
       "3872   Central America is part of the Mesoamerican bi...  \n",
       "3876   It has a density of 77 people per square kilom...  \n",
       "3872   Central America is part of the Mesoamerican bi...  \n",
       "8031   The Union marshaled the resources and manpower...  \n",
       "\n",
       "[8484 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8484/8484 [00:29<00:00, 290.37it/s]\n"
     ]
    }
   ],
   "source": [
    "question = np.array([fsa.transform(i) for i in tqdm(df['Question'].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8484/8484 [00:02<00:00, 3296.37it/s]\n"
     ]
    }
   ],
   "source": [
    "Positive = np.array([fsa.transform(i) for i in tqdm(df['Pos_answer'].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8484/8484 [00:02<00:00, 3673.54it/s]\n"
     ]
    }
   ],
   "source": [
    "Negative = np.array([fsa.transform(i) for i in tqdm(df['Neg_answer'].values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('question', question)\n",
    "np.save('Positive', Positive)\n",
    "np.save('Negative', Negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = np.load('question.npy')\n",
    "negative = np.load('Negative.npy')\n",
    "positive = np.load('Positive.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rando = np.arange(len(question))\n",
    "np.random.shuffle(rando)\n",
    "question,negative,positive = question[rando],negative[rando],positive[rando]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triplet Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Triplet Loss Function](triplet.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true,y_pred):\n",
    "    \n",
    "    \n",
    "    positive_pred = y_pred[:,1]\n",
    "    negative_pred = y_pred[:,0]\n",
    "    \n",
    "    sum_loss = 1 - positive_pred + negative_pred\n",
    "    \n",
    "    loss = K.maximum(sum_loss,0.0)\n",
    "    \n",
    "    return K.mean(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIEMASE + TRIPLET + Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Triplet Loss Function](nn.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = Input(shape=(20,300), name = 'n')\n",
    "mid_input = Input(shape=(20,300), name = 'q')\n",
    "right_input = Input(shape=(20,300), name = 'p')\n",
    "\n",
    "conv1 = layers.Conv1D(128,5, activation='tanh',kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "max_pool1 = layers.MaxPooling1D(3)\n",
    "\n",
    "conv2 = layers.Conv1D(256, 3, activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "max_pool2 = layers.MaxPooling1D(2)\n",
    "avg_pool2 = layers.AveragePooling1D(2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "flatten = layers.Flatten()\n",
    "\n",
    "\n",
    "left_output = conv1(left_input)\n",
    "left_output = max_pool1(left_output)\n",
    "\n",
    "left_output = conv2(left_output)\n",
    "left_output = layers.concatenate([max_pool2(left_output),avg_pool2(left_output)], axis = -1)\n",
    "\n",
    "left_output = flatten(left_output)\n",
    "\n",
    "\n",
    "mid_output = conv1(mid_input)\n",
    "mid_output = max_pool1(mid_output)\n",
    "\n",
    "mid_output = conv2(mid_output)\n",
    "mid_output = layers.concatenate([max_pool2(mid_output),avg_pool2(mid_output)], axis = -1)\n",
    "\n",
    "mid_output = flatten(mid_output)\n",
    "\n",
    "\n",
    "right_output = conv1(right_input)\n",
    "right_output = max_pool1(right_output)\n",
    "\n",
    "right_output = conv2(right_output)\n",
    "right_output = layers.concatenate([max_pool2(right_output),avg_pool2(right_output)], axis = -1)\n",
    "\n",
    "right_output = flatten(right_output)\n",
    "\n",
    "\n",
    "\n",
    "merged_L = layers.concatenate([left_output, mid_output], axis=-1)\n",
    "merged_R = layers.concatenate([right_output, mid_output], axis=-1)\n",
    "\n",
    "\n",
    "dens1 = layers.Dense(256,activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "droprout1 = layers.Dropout(0.05)\n",
    "\n",
    "merged_L = droprout1(dens1(merged_L))\n",
    "merged_R = droprout1(dens1(merged_R))\n",
    "\n",
    "\n",
    "\n",
    "dens2 = layers.Dense(256, activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "dens_pred = layers.Dense(1, activation='softmax',kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "pred_L = dens_pred(dens2(merged_L))\n",
    "pred_R = dens_pred(dens2(merged_R))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred = layers.concatenate([pred_L,pred_R], axis = -1)\n",
    "\n",
    "model = Model(inputs = [left_input, mid_input, right_input], outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "n (InputLayer)                  (None, 20, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "q (InputLayer)                  (None, 20, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "p (InputLayer)                  (None, 20, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 16, 128)      192128      n[0][0]                          \n",
      "                                                                 q[0][0]                          \n",
      "                                                                 p[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 5, 128)       0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "                                                                 conv1d_1[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 3, 256)       98560       max_pooling1d_1[0][0]            \n",
      "                                                                 max_pooling1d_1[1][0]            \n",
      "                                                                 max_pooling1d_1[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1, 256)       0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "                                                                 conv1d_2[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 1, 256)       0           conv1d_2[0][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "                                                                 conv1d_2[2][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 512)       0           max_pooling1d_2[0][0]            \n",
      "                                                                 average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 512)       0           max_pooling1d_2[1][0]            \n",
      "                                                                 average_pooling1d_1[1][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 512)       0           max_pooling1d_2[2][0]            \n",
      "                                                                 average_pooling1d_1[2][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1024)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 1024)         0           flatten_1[2][0]                  \n",
      "                                                                 flatten_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          262400      concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "                                                                 dropout_1[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            257         dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 2)            0           dense_3[0][0]                    \n",
      "                                                                 dense_3[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 619,137\n",
      "Trainable params: 619,137\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=triplet_loss, \n",
    "              optimizer=optimizers.Adam(lr = 0.01,beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelLSTM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type _io.BufferedWriter)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e5364896717e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'modelConv.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type _io.BufferedWriter)"
     ]
    }
   ],
   "source": [
    "with open('modelConv.pkl', 'wb') as output:\n",
    "    pickle.dumps(model, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8484/8484 [==============================] - 5s 574us/step - loss: 1.0025\n",
      "Epoch 2/100\n",
      "8484/8484 [==============================] - 4s 520us/step - loss: 1.0000\n",
      "Epoch 3/100\n",
      "8484/8484 [==============================] - 5s 581us/step - loss: 1.0000\n",
      "Epoch 4/100\n",
      "8484/8484 [==============================] - 5s 629us/step - loss: 1.0000\n",
      "Epoch 5/100\n",
      "8484/8484 [==============================] - 5s 583us/step - loss: 1.0000\n",
      "Epoch 6/100\n",
      "8484/8484 [==============================] - 5s 612us/step - loss: 1.0000\n",
      "Epoch 7/100\n",
      "8484/8484 [==============================] - 5s 575us/step - loss: 1.0000\n",
      "Epoch 8/100\n",
      "8484/8484 [==============================] - 5s 572us/step - loss: 1.0000\n",
      "Epoch 9/100\n",
      "8484/8484 [==============================] - 5s 637us/step - loss: 1.0000\n",
      "Epoch 10/100\n",
      "8484/8484 [==============================] - 5s 553us/step - loss: 1.0000\n",
      "Epoch 11/100\n",
      "8484/8484 [==============================] - 5s 544us/step - loss: 1.0000\n",
      "Epoch 12/100\n",
      "8484/8484 [==============================] - 5s 639us/step - loss: 1.0000\n",
      "Epoch 13/100\n",
      "8484/8484 [==============================] - 6s 657us/step - loss: 1.0000\n",
      "Epoch 14/100\n",
      "8484/8484 [==============================] - 5s 583us/step - loss: 1.0000\n",
      "Epoch 15/100\n",
      "8484/8484 [==============================] - 5s 575us/step - loss: 1.0000\n",
      "Epoch 16/100\n",
      "8484/8484 [==============================] - 5s 613us/step - loss: 1.0000\n",
      "Epoch 17/100\n",
      "8484/8484 [==============================] - 5s 551us/step - loss: 1.0000\n",
      "Epoch 18/100\n",
      "8484/8484 [==============================] - 5s 556us/step - loss: 1.0000\n",
      "Epoch 19/100\n",
      "8484/8484 [==============================] - 5s 589us/step - loss: 1.0000\n",
      "Epoch 20/100\n",
      "8484/8484 [==============================] - 5s 563us/step - loss: 1.0000\n",
      "Epoch 21/100\n",
      "8484/8484 [==============================] - 5s 544us/step - loss: 1.0000\n",
      "Epoch 22/100\n",
      "8484/8484 [==============================] - 5s 622us/step - loss: 1.0000\n",
      "Epoch 23/100\n",
      "8484/8484 [==============================] - 5s 558us/step - loss: 1.0000\n",
      "Epoch 24/100\n",
      "8484/8484 [==============================] - 5s 570us/step - loss: 1.0000\n",
      "Epoch 25/100\n",
      "8484/8484 [==============================] - 5s 557us/step - loss: 1.0000\n",
      "Epoch 26/100\n",
      "8484/8484 [==============================] - 5s 534us/step - loss: 1.0000\n",
      "Epoch 27/100\n",
      "8484/8484 [==============================] - 4s 528us/step - loss: 1.0000\n",
      "Epoch 28/100\n",
      "8484/8484 [==============================] - 5s 540us/step - loss: 1.0000\n",
      "Epoch 29/100\n",
      "8484/8484 [==============================] - 5s 553us/step - loss: 1.0000\n",
      "Epoch 30/100\n",
      "8484/8484 [==============================] - 5s 535us/step - loss: 1.0000\n",
      "Epoch 31/100\n",
      "8484/8484 [==============================] - 4s 527us/step - loss: 1.0000\n",
      "Epoch 32/100\n",
      "8484/8484 [==============================] - 5s 547us/step - loss: 1.0000\n",
      "Epoch 33/100\n",
      "8484/8484 [==============================] - 5s 534us/step - loss: 1.0000\n",
      "Epoch 34/100\n",
      "8484/8484 [==============================] - 4s 528us/step - loss: 1.0000\n",
      "Epoch 35/100\n",
      "8484/8484 [==============================] - 4s 523us/step - loss: 1.0000\n",
      "Epoch 36/100\n",
      "8484/8484 [==============================] - 5s 536us/step - loss: 1.0000\n",
      "Epoch 37/100\n",
      "8484/8484 [==============================] - 5s 532us/step - loss: 1.0000\n",
      "Epoch 38/100\n",
      "8484/8484 [==============================] - 5s 534us/step - loss: 1.0000\n",
      "Epoch 39/100\n",
      "8484/8484 [==============================] - 5s 534us/step - loss: 1.0000\n",
      "Epoch 40/100\n",
      "8484/8484 [==============================] - 5s 545us/step - loss: 1.0000\n",
      "Epoch 41/100\n",
      "8484/8484 [==============================] - 5s 532us/step - loss: 1.0000\n",
      "Epoch 42/100\n",
      "8484/8484 [==============================] - 5s 534us/step - loss: 1.0000\n",
      "Epoch 43/100\n",
      "8484/8484 [==============================] - 5s 533us/step - loss: 1.0000\n",
      "Epoch 44/100\n",
      "8484/8484 [==============================] - 5s 538us/step - loss: 1.0000\n",
      "Epoch 45/100\n",
      "8484/8484 [==============================] - 5s 557us/step - loss: 1.0000\n",
      "Epoch 46/100\n",
      "8484/8484 [==============================] - 5s 537us/step - loss: 1.0000\n",
      "Epoch 47/100\n",
      "8484/8484 [==============================] - 5s 540us/step - loss: 1.0000\n",
      "Epoch 48/100\n",
      "8484/8484 [==============================] - 5s 539us/step - loss: 1.0000\n",
      "Epoch 49/100\n",
      "8484/8484 [==============================] - 5s 564us/step - loss: 1.0000\n",
      "Epoch 50/100\n",
      "8484/8484 [==============================] - 5s 586us/step - loss: 1.0000\n",
      "Epoch 51/100\n",
      "8484/8484 [==============================] - 4s 527us/step - loss: 1.0000\n",
      "Epoch 52/100\n",
      "8484/8484 [==============================] - 4s 514us/step - loss: 1.0000\n",
      "Epoch 53/100\n",
      "8484/8484 [==============================] - 5s 548us/step - loss: 1.0000\n",
      "Epoch 54/100\n",
      "8484/8484 [==============================] - 5s 595us/step - loss: 1.0000\n",
      "Epoch 55/100\n",
      "8484/8484 [==============================] - 4s 524us/step - loss: 1.0000\n",
      "Epoch 56/100\n",
      "8484/8484 [==============================] - 4s 514us/step - loss: 1.0000\n",
      "Epoch 57/100\n",
      "8484/8484 [==============================] - 4s 512us/step - loss: 1.0000\n",
      "Epoch 58/100\n",
      "8484/8484 [==============================] - 4s 509us/step - loss: 1.0000\n",
      "Epoch 59/100\n",
      "8484/8484 [==============================] - 5s 533us/step - loss: 1.0000\n",
      "Epoch 60/100\n",
      "8484/8484 [==============================] - 5s 581us/step - loss: 1.0000\n",
      "Epoch 61/100\n",
      "8484/8484 [==============================] - 6s 670us/step - loss: 1.0000\n",
      "Epoch 62/100\n",
      "8484/8484 [==============================] - 5s 602us/step - loss: 1.0000\n",
      "Epoch 63/100\n",
      "8484/8484 [==============================] - 5s 537us/step - loss: 1.0000\n",
      "Epoch 64/100\n",
      "8484/8484 [==============================] - 5s 551us/step - loss: 1.0000\n",
      "Epoch 65/100\n",
      "8484/8484 [==============================] - 5s 550us/step - loss: 1.0000\n",
      "Epoch 66/100\n",
      "8484/8484 [==============================] - 5s 602us/step - loss: 1.0000\n",
      "Epoch 67/100\n",
      "8484/8484 [==============================] - 5s 579us/step - loss: 1.0000\n",
      "Epoch 68/100\n",
      "8484/8484 [==============================] - 5s 598us/step - loss: 1.0000\n",
      "Epoch 69/100\n",
      "8484/8484 [==============================] - 5s 569us/step - loss: 1.0000\n",
      "Epoch 70/100\n",
      "8484/8484 [==============================] - 5s 589us/step - loss: 1.0000\n",
      "Epoch 71/100\n",
      "8484/8484 [==============================] - 5s 568us/step - loss: 1.0000\n",
      "Epoch 72/100\n",
      "8484/8484 [==============================] - 5s 560us/step - loss: 1.0000\n",
      "Epoch 73/100\n",
      "8484/8484 [==============================] - 5s 568us/step - loss: 1.0000\n",
      "Epoch 74/100\n",
      "8484/8484 [==============================] - 5s 580us/step - loss: 1.0000\n",
      "Epoch 75/100\n",
      "8484/8484 [==============================] - 5s 592us/step - loss: 1.0000\n",
      "Epoch 76/100\n",
      "8484/8484 [==============================] - 5s 571us/step - loss: 1.0000\n",
      "Epoch 77/100\n",
      "8484/8484 [==============================] - 5s 626us/step - loss: 1.0000\n",
      "Epoch 78/100\n",
      "8484/8484 [==============================] - 5s 549us/step - loss: 1.0000\n",
      "Epoch 79/100\n",
      "8484/8484 [==============================] - 4s 492us/step - loss: 1.0000\n",
      "Epoch 80/100\n",
      "8484/8484 [==============================] - 5s 565us/step - loss: 1.0000\n",
      "Epoch 81/100\n",
      "8484/8484 [==============================] - 5s 544us/step - loss: 1.0000\n",
      "Epoch 82/100\n",
      "8484/8484 [==============================] - 5s 593us/step - loss: 1.0000\n",
      "Epoch 83/100\n",
      "8484/8484 [==============================] - 5s 618us/step - loss: 1.0000\n",
      "Epoch 84/100\n",
      "8484/8484 [==============================] - 5s 580us/step - loss: 1.0000\n",
      "Epoch 85/100\n",
      "8484/8484 [==============================] - 5s 609us/step - loss: 1.0000\n",
      "Epoch 86/100\n",
      "8484/8484 [==============================] - 5s 615us/step - loss: 1.0000\n",
      "Epoch 87/100\n",
      "8484/8484 [==============================] - 5s 562us/step - loss: 1.0000\n",
      "Epoch 88/100\n",
      "8484/8484 [==============================] - 6s 664us/step - loss: 1.0000\n",
      "Epoch 89/100\n",
      "8484/8484 [==============================] - 5s 640us/step - loss: 1.0000\n",
      "Epoch 90/100\n",
      "8484/8484 [==============================] - 5s 620us/step - loss: 1.0000\n",
      "Epoch 91/100\n",
      "8484/8484 [==============================] - 5s 636us/step - loss: 1.0000\n",
      "Epoch 92/100\n",
      "8484/8484 [==============================] - 5s 626us/step - loss: 1.0000\n",
      "Epoch 93/100\n",
      "8484/8484 [==============================] - 5s 620us/step - loss: 1.0000\n",
      "Epoch 94/100\n",
      "8484/8484 [==============================] - 5s 626us/step - loss: 1.0000\n",
      "Epoch 95/100\n",
      "8484/8484 [==============================] - 5s 610us/step - loss: 1.0000\n",
      "Epoch 96/100\n",
      "8484/8484 [==============================] - 5s 611us/step - loss: 1.0000\n",
      "Epoch 97/100\n",
      "8484/8484 [==============================] - 5s 613us/step - loss: 1.0000\n",
      "Epoch 98/100\n",
      "8484/8484 [==============================] - 5s 602us/step - loss: 1.0000\n",
      "Epoch 99/100\n",
      "8484/8484 [==============================] - 5s 591us/step - loss: 1.0000\n",
      "Epoch 100/100\n",
      "8484/8484 [==============================] - 6s 660us/step - loss: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit({'n' : negative, 'q' : question, 'p' : positive},\n",
    "          np.zeros(len(question)),   \n",
    "          epochs=100, \n",
    "          batch_size = 50,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2dba0eba2e8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2db920c6dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIEMASE + Cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_log_softmax(x):\n",
    "    return K.log(K.softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = Input(shape=(20,300), name = 'n')\n",
    "mid_input = Input(shape=(20,300), name = 'q')\n",
    "# right_input = Input(shape=(20,300), name = 'p')\n",
    "\n",
    "conv1 = layers.Conv1D(128,5, activation='tanh',kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "max_pool1 = layers.MaxPooling1D(3)\n",
    "\n",
    "conv2 = layers.Conv1D(256, 3, activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "max_pool2 = layers.MaxPooling1D(2)\n",
    "avg_pool2 = layers.AveragePooling1D(2)\n",
    "\n",
    "flatten = layers.Flatten()\n",
    "\n",
    "left_output = conv1(left_input)\n",
    "left_output = max_pool1(left_output)\n",
    "\n",
    "left_output = conv2(left_output)\n",
    "left_output = layers.concatenate([max_pool2(left_output),avg_pool2(left_output)], axis = -1)\n",
    "\n",
    "left_output = flatten(left_output)\n",
    "\n",
    "\n",
    "mid_output = conv1(mid_input)\n",
    "mid_output = max_pool1(mid_output)\n",
    "\n",
    "mid_output = conv2(mid_output)\n",
    "mid_output = layers.concatenate([max_pool2(mid_output),avg_pool2(mid_output)], axis = -1)\n",
    "\n",
    "mid_output = flatten(mid_output)\n",
    "\n",
    "\n",
    "\n",
    "merged_L = layers.concatenate([left_output, mid_output], axis=-1)\n",
    "# merged_R = layers.concatenate([right_output, mid_output], axis=-1)\n",
    "\n",
    "\n",
    "dens1 = layers.Dense(256,activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "droprout1 = layers.Dropout(0.5)\n",
    "\n",
    "merged_L = droprout1(dens1(merged_L))\n",
    "# merged_R = droprout1(dens1(merged_R))\n",
    "\n",
    "\n",
    "\n",
    "dens2 = layers.Dense(256, activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "dens_pred = layers.Dense(1, activation=my_log_softmax,kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "# pred_L = dens_pred(dens2(merged_L))\n",
    "# pred_R = dens_pred(dens2(merged_R))\n",
    "\n",
    "dens_pred = dens_pred(dens2(merged_L))\n",
    "\n",
    "\n",
    "# pred = layers.concatenate([pred_L,pred_R], axis = -1)\n",
    "\n",
    "model = Model(inputs = [left_input, mid_input], outputs = dens_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelCrossEntropy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "etyk = np.random.randint(2, size=len(question)).astype(float)\n",
    "etyk[etyk > 0.0] = .99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 5s - loss: 0.0143\n",
      "Epoch 2/10\n",
      " - 4s - loss: 3.6975e-06\n",
      "Epoch 3/10\n",
      " - 4s - loss: 8.0356e-10\n",
      "Epoch 4/10\n",
      " - 4s - loss: 1.1099e-13\n",
      "Epoch 5/10\n",
      " - 4s - loss: 6.8911e-19\n",
      "Epoch 6/10\n",
      " - 5s - loss: 4.9822e-27\n",
      "Epoch 7/10\n",
      " - 4s - loss: 1.9228e-34\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0000e+00\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dba1107588>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit({'n' : negative, 'q' : question, 'p' : positive},\n",
    "          etyk,          \n",
    "          epochs=10, \n",
    "          batch_size = 50,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIEMASE + TRIPLET + LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "left_input = Input(shape=(20,300), name = 'n')\n",
    "mid_input = Input(shape=(20,300), name = 'q')\n",
    "right_input = Input(shape=(20,300), name = 'p')\n",
    "\n",
    "lstm1 = layers.LSTM(50, kernel_regularizer = regularizers.l2(1e-4), input_shape = (None,20,300))\n",
    "#conv1 = layers.Conv1D(128,5, activation='tanh',kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "max_pool1 = layers.MaxPooling1D(2)\n",
    "\n",
    "lstm2 = layers.LSTM(50, kernel_regularizer = regularizers.l2(1e-4), input_shape = (None,20,300))\n",
    "#conv2 = layers.Conv1D(256, 3, activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "max_pool2 = layers.MaxPooling1D(2)\n",
    "avg_pool2 = layers.AveragePooling1D(2)\n",
    "\n",
    "\n",
    "flatten = layers.Flatten()\n",
    "\n",
    "\n",
    "left_output = lstm1(left_input)\n",
    "left_output = max_pool1(left_output)\n",
    "\n",
    "left_output = lstm2(left_output)\n",
    "left_output = layers.concatenate([max_pool2(left_output),avg_pool2(left_output)], axis = -1)\n",
    "\n",
    "left_output = flatten(left_output)\n",
    "\n",
    "\n",
    "mid_output = lstm1(mid_input)\n",
    "mid_output = max_pool1(mid_output)\n",
    "\n",
    "mid_output = lstm2(mid_output)\n",
    "mid_output = layers.concatenate([max_pool2(mid_output),avg_pool2(mid_output)], axis = -1)\n",
    "\n",
    "mid_output = flatten(mid_output)\n",
    "\n",
    "\n",
    "right_output = lstm1(right_input)\n",
    "right_output = max_pool1(right_output)\n",
    "\n",
    "right_output = lstm2(right_output)\n",
    "right_output = layers.concatenate([max_pool2(right_output),avg_pool2(right_output)], axis = -1)\n",
    "\n",
    "right_output = flatten(right_output)\n",
    "\n",
    "\n",
    "\n",
    "merged_L = layers.concatenate([left_output, mid_output], axis=-1)\n",
    "merged_R = layers.concatenate([right_output, mid_output], axis=-1)\n",
    "\n",
    "\n",
    "dens1 = layers.Dense(256,activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "droprout1 = layers.Dropout(0.05)\n",
    "\n",
    "merged_L = droprout1(dens1(merged_L))\n",
    "merged_R = droprout1(dens1(merged_R))\n",
    "\n",
    "\n",
    "\n",
    "dens2 = layers.Dense(256, activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "dens_pred = layers.Dense(1, activation='softmax',kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "pred_L = dens_pred(dens2(merged_L))\n",
    "pred_R = dens_pred(dens2(merged_R))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred = layers.concatenate([pred_L,pred_R], axis = -1)\n",
    "\n",
    "model = Model(inputs = [left_input, mid_input, right_input], outputs = pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8484/8484 [==============================] - 4s 524us/step - loss: 1.0000\n",
      "Epoch 2/10\n",
      "8484/8484 [==============================] - 5s 546us/step - loss: 1.0000\n",
      "Epoch 3/10\n",
      "8484/8484 [==============================] - 5s 562us/step - loss: 1.0000\n",
      "Epoch 4/10\n",
      "8484/8484 [==============================] - 5s 543us/step - loss: 1.0000\n",
      "Epoch 5/10\n",
      "8484/8484 [==============================] - 5s 547us/step - loss: 1.0000\n",
      "Epoch 6/10\n",
      "8484/8484 [==============================] - 5s 564us/step - loss: 1.0000\n",
      "Epoch 7/10\n",
      "8484/8484 [==============================] - 5s 582us/step - loss: 1.0000\n",
      "Epoch 8/10\n",
      "8484/8484 [==============================] - 4s 528us/step - loss: 1.0000\n",
      "Epoch 9/10\n",
      "8484/8484 [==============================] - 5s 619us/step - loss: 1.0000\n",
      "Epoch 10/10\n",
      "8484/8484 [==============================] - 5s 593us/step - loss: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit({'n' : negative, 'q' : question, 'p' : positive},\n",
    "          np.zeros(len(question)),   \n",
    "          epochs=10, \n",
    "          batch_size = 50,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese + Trilpet exacly as in Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_input = Input(shape=(20,300), name = 'n')\n",
    "mid_input = Input(shape=(20,300), name = 'q')\n",
    "right_input = Input(shape=(20,300), name = 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window size  = 3\n",
    "conv1_min_window_size_3 = layers.Conv1D(300,3, activation='tanh',\n",
    "                                        kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "min_pool_1_size_3 = layers.GlobalMaxPooling1D()\n",
    "\n",
    "conv1_max_window_size_3 = layers.Conv1D(300,3, activation='tanh',\n",
    "                                        kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "max_pool_1_size_3 = layers.GlobalMaxPooling1D()\n",
    "\n",
    "conv1_avg_window_size_3 = layers.Conv1D(300,3, activation='tanh',\n",
    "                                        kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "avg_pool_1_size_3 = layers.GlobalAveragePooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window size  = 2\n",
    "conv1_min_window_size_2 = layers.Conv1D(300,2, activation='tanh',\n",
    "                                        kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "min_pool_1_size_2 = layers.GlobalMaxPooling1D()\n",
    "\n",
    "conv1_max_window_size_2 = layers.Conv1D(300,2, activation='tanh',\n",
    "                                        kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "max_pool_1_size_2 = layers.GlobalMaxPooling1D()\n",
    "\n",
    "conv1_avg_window_size_2 = layers.Conv1D(300,2, activation='tanh',\n",
    "                                        kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,300))\n",
    "avg_pool_1_size_2 = layers.GlobalAveragePooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window size  = Infty = 20\n",
    "min_pool_1_size_20 = layers.GlobalMaxPooling1D()\n",
    "\n",
    "max_pool_1_size_20 = layers.GlobalMaxPooling1D()\n",
    "\n",
    "avg_pool_1_size_20 = layers.GlobalAveragePooling1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As there is no MinPooling in Keras, I use MaxPooling from - 1 * vector\n",
    "\n",
    "left_size3_max = max_pool_1_size_3(conv1_max_window_size_3(left_input))\n",
    "left_size3_min = min_pool_1_size_3(layers.Lambda(lambda x : x * -1 )(conv1_min_window_size_3(left_input)))\n",
    "left_size3_avg = avg_pool_1_size_3(conv1_avg_window_size_3(left_input))\n",
    "\n",
    "mid_size3_max = max_pool_1_size_3(conv1_max_window_size_3(mid_input))\n",
    "mid_size3_min = min_pool_1_size_3(layers.Lambda(lambda x : x * -1 )(conv1_min_window_size_3(mid_input)))\n",
    "mid_size3_avg = avg_pool_1_size_3(conv1_avg_window_size_3(mid_input))\n",
    "\n",
    "right_size3_max = max_pool_1_size_3(conv1_max_window_size_3(right_input))\n",
    "right_size3_min = min_pool_1_size_3(layers.Lambda(lambda x : x * -1 )(conv1_min_window_size_3(right_input)))\n",
    "right_size3_avg = avg_pool_1_size_3(conv1_avg_window_size_3(right_input))\n",
    "\n",
    "\n",
    "\n",
    "left_size2_max  = max_pool_1_size_2(conv1_max_window_size_2(left_input))\n",
    "left_size2_min = min_pool_1_size_2(layers.Lambda(lambda x : x * -1 )(conv1_min_window_size_2(left_input)))\n",
    "left_size2_avg = avg_pool_1_size_2(conv1_avg_window_size_2(left_input))\n",
    "\n",
    "mid_size2_max = max_pool_1_size_2(conv1_max_window_size_2(mid_input))\n",
    "mid_size2_min = min_pool_1_size_2(layers.Lambda(lambda x : x * -1 )(conv1_min_window_size_2(mid_input)))\n",
    "mid_size2_avg = avg_pool_1_size_2(conv1_avg_window_size_2(mid_input))\n",
    "\n",
    "right_size2_max = max_pool_1_size_2(conv1_max_window_size_3(right_input))\n",
    "right_size2_min = min_pool_1_size_2(layers.Lambda(lambda x : x * -1 )(conv1_min_window_size_3(right_input)))\n",
    "right_size2_avg = avg_pool_1_size_2(conv1_avg_window_size_3(right_input))\n",
    "\n",
    "\n",
    "\n",
    "left_sizeInf_max  = max_pool_1_size_20(left_input)\n",
    "left_sizeInf_min = min_pool_1_size_20(layers.Lambda(lambda x : x * -1 )(left_input))\n",
    "left_sizeInf_avg = avg_pool_1_size_20(left_input)\n",
    "\n",
    "mid_sizeInf_max = max_pool_1_size_20(mid_input)\n",
    "mid_sizeInf_min = min_pool_1_size_20(layers.Lambda(lambda x : x * -1 )(mid_input))\n",
    "mid_sizeInf_avg = avg_pool_1_size_20(mid_input)\n",
    "\n",
    "right_sizeInf_max = max_pool_1_size_20(right_input)\n",
    "right_sizeInf_min = min_pool_1_size_20(layers.Lambda(lambda x : x * -1 )(right_input))\n",
    "right_sizeInf_avg = avg_pool_1_size_20(right_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-dimension filters\n",
    "   \n",
    "per_dimension_layers_size_2_max = \\\n",
    "[[layers.Conv1D(3,2, activation='tanh',kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,1))]\n",
    "for i in range(300)]\n",
    "\n",
    "\n",
    "per_dimension_layers_size_3_max = \\\n",
    "[[layers.Conv1D(3,3, activation='tanh',kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,1))]\n",
    "for i in range(300)]\n",
    "\n",
    "\n",
    "per_dimension_layers_size_2_min = \\\n",
    "[[layers.Conv1D(3,2, activation='tanh',kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,1))]\n",
    "for i in range(300)]\n",
    "\n",
    "\n",
    "per_dimension_layers_size_3_min = \\\n",
    "[[layers.Conv1D(3,3, activation='tanh',kernel_regularizer=regularizers.l2(1e-4),input_shape = (None,20,1))]\n",
    "for i in range(300)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-88792056c99d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     (per_dimension_layers_size_2_max[i][0](        \n\u001b[1;32m      6\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     ))) for i in range(300)]\n\u001b[0m\u001b[1;32m      8\u001b[0m left_single_dimension_min_size2 = [layers.GlobalMaxPooling1D()(\n\u001b[1;32m      9\u001b[0m     (per_dimension_layers_size_2_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
      "\u001b[0;32m<ipython-input-28-88792056c99d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     (per_dimension_layers_size_2_max[i][0](        \n\u001b[1;32m      6\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     ))) for i in range(300)]\n\u001b[0m\u001b[1;32m      8\u001b[0m left_single_dimension_min_size2 = [layers.GlobalMaxPooling1D()(\n\u001b[1;32m      9\u001b[0m     (per_dimension_layers_size_2_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    590\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    591\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    136\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             self.bias = self.add_weight(shape=(self.filters,),\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[1;32m    414\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             return K.random_uniform(shape, -limit, limit,\n\u001b[0;32m--> 217\u001b[0;31m                                     dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m   3836\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3837\u001b[0m     return tf.random_uniform(shape, minval=minval, maxval=maxval,\n\u001b[0;32m-> 3838\u001b[0;31m                              dtype=dtype, seed=seed)\n\u001b[0m\u001b[1;32m   3839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ShapeTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0mminval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"min\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mmaxval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"max\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1012\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    233\u001b[0m                                          as_ref=False):\n\u001b[1;32m    234\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m       attrs={\"value\": tensor_value,\n\u001b[1;32m    219\u001b[0m              \"dtype\": dtype_value},\n\u001b[0;32m--> 220\u001b[0;31m       name=name).outputs[0]\n\u001b[0m\u001b[1;32m    221\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconst_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3390\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m       \u001b[0;31m# Note: shapes are lazily computed with the C API enabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1760\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1762\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_control_flow_post_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_control_flow_post_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0mavailable\u001b[0m \u001b[0mbefore\u001b[0m \u001b[0mcalling\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m     \"\"\"\n\u001b[0;32m-> 1768\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m       \u001b[0mcontrol_flow_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckInputFromValidContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_control_flow_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2114\u001b[0m         retval = [\n\u001b[1;32m   2115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2116\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtf_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2117\u001b[0m         ]\n\u001b[1;32m   2118\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2113\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m         retval = [\n\u001b[0;32m-> 2115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtf_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m         ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Per dimension filters cd\n",
    "\n",
    " \n",
    "left_single_dimension_max_size2 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_2_max[i][0](        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(left_input))\n",
    "    ))) for i in range(300)]\n",
    "left_single_dimension_min_size2 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_2_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(left_input))\n",
    "    )))) for i in range(300)]\n",
    "\n",
    "left_single_dimension_max_size3 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_3_max[i][0](        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(left_input))\n",
    "    ))) for i in range(300)]\n",
    "left_single_dimension_min_size3 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_3_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(left_input))\n",
    "    )))) for i in range(300)]\n",
    "\n",
    "\n",
    "right_single_dimension_max_size2 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_2_max[i][0](        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(right_input))\n",
    "    ))) for i in range(300)]\n",
    "right_single_dimension_min_size2 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_2_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(right_input))\n",
    "    )))) for i in range(300)]\n",
    "\n",
    "right_single_dimension_max_size3 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_3_max[i][0](        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(right_input))\n",
    "    ))) for i in range(300)]\n",
    "right_single_dimension_min_size3 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_3_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(right_input))\n",
    "    )))) for i in range(300)]\n",
    "\n",
    "\n",
    "mid_single_dimension_max_size2 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_2_max[i][0](        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(mid_input))\n",
    "    ))) for i in range(300)]\n",
    "mid_single_dimension_min_size2 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_2_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(mid_input))\n",
    "    )))) for i in range(300)]\n",
    "\n",
    "mid_single_dimension_max_size3 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_3_max[i][0](        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(mid_input))\n",
    "    ))) for i in range(300)]\n",
    "mid_single_dimension_min_size3 = [layers.GlobalMaxPooling1D()(\n",
    "    (per_dimension_layers_size_3_min[i][0](layers.Lambda(lambda x : x * -1 )(        \n",
    "    layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],3,1]) )(layers.Lambda(lambda x : x[:,:,i])(mid_input))\n",
    "    )))) for i in range(300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal comparison, AKA Algorithm 1 - cosine distance + L2 distance\n",
    "\n",
    "\n",
    "results_L = []\n",
    "for gather in ['avg','max','min']:\n",
    "  \n",
    "    results_L1 = [layers.dot([\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('left_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('left_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('left_sizeInf_%s'%(gather))))      \n",
    "      ]),\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_sizeInf_%s'%(gather))))      \n",
    "      ])\n",
    "    ],axes = -1,normalize=True) for i in range(300)]\n",
    "\n",
    "\n",
    "    results_L2 = [layers.Lambda(lambda x : tf.norm(x,ord = 2,axis=-1,keepdims=True))\n",
    "        (layers.subtract([\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('left_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('left_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('left_sizeInf_%s'%(gather))))      \n",
    "        ]),\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_sizeInf_%s'%(gather))))      \n",
    "      ])\n",
    "    ])) for i in range(300)]\n",
    "\n",
    "\n",
    "    results_L += results_L1\n",
    "    results_L += results_L2\n",
    "\n",
    "horizontal_left_compared = layers.concatenate(results_L)\n",
    "\n",
    "del results_L\n",
    "del results_L1\n",
    "del results_L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal comparison, AKA Algorithm 1 - cosine distance + L2 distance\n",
    "\n",
    "\n",
    "results_R = []\n",
    "for gather in ['avg','max','min']:\n",
    "  \n",
    "    results_R1 = [layers.dot([\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('right_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('right_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('right_sizeInf_%s'%(gather))))      \n",
    "      ]),\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_sizeInf_%s'%(gather))))      \n",
    "      ])\n",
    "    ],axes = -1,normalize=True) for i in range(300)]\n",
    "\n",
    "\n",
    "    results_R2 = [layers.Lambda(lambda x : tf.norm(x,ord = 2,axis=-1,keepdims=True))\n",
    "        (layers.subtract([\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('right_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('right_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('right_sizeInf_%s'%(gather))))      \n",
    "        ]),\n",
    "        layers.concatenate( [\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size2_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_size3_%s'%(gather)))),\n",
    "\n",
    "        layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1]) )\n",
    "        (layers.Lambda(lambda x : x[:,i])(eval('mid_sizeInf_%s'%(gather))))      \n",
    "      ])\n",
    "    ])) for i in range(300)]\n",
    "\n",
    "\n",
    "    results_R += results_R1\n",
    "    results_R += results_R2\n",
    "    \n",
    "horizontal_right_compared = layers.concatenate(results_R)\n",
    "\n",
    "del results_R\n",
    "del results_R1\n",
    "del results_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertical comparison,AKA Algorithm 2 - cosine distance + L2 distance + L1 distance\n",
    "\n",
    "v_results_L = []\n",
    "for gather in ['avg','max','min']:\n",
    "    for num,s1 in enumerate(['2','3','Inf']): \n",
    "        for s2 in ['2','3','Inf'][num:]:\n",
    "        \n",
    "            \n",
    "            v_results_L.append(layers.dot([\n",
    "                    eval('left_size%s_%s'%(s1,gather)),eval('mid_size%s_%s'%(s2,gather))\n",
    "                ],axes = -1,normalize=True))\n",
    "            v_results_L.append(layers.Lambda(lambda x : tf.norm(x,ord = 2,axis=-1,keepdims=True))\n",
    "                         (layers.subtract([\n",
    "                    eval('left_size%s_%s'%(s1,gather)),eval('mid_size%s_%s'%(s2,gather))])))\n",
    "            v_results_L.append(layers.Lambda(lambda x : tf.norm(x,ord = 1,axis=-1,keepdims=True))\n",
    "                         (layers.subtract([\n",
    "                    eval('left_size%s_%s'%(s1,gather)),eval('mid_size%s_%s'%(s2,gather))])))    \n",
    "\n",
    "    if gather != 'avg':\n",
    "        for s1 in ['2','3']:    \n",
    "            \n",
    "            v_results_L1 = [layers.dot([\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('left_single_dimension_%s_size%s'%(gather,s1))]),\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('mid_single_dimension_%s_size%s'%(gather,s1))])\n",
    "            ],axes = -1,normalize=True) for i in range(3)]\n",
    "\n",
    "            v_results_L2 = [layers.Lambda(lambda x : tf.norm(x,ord = 2,axis=-1,keepdims=True))\n",
    "                (layers.subtract([\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('left_single_dimension_%s_size%s'%(gather,s1))]),\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('mid_single_dimension_%s_size%s'%(gather,s1))])\n",
    "            ])) for i in range(3)]\n",
    "\n",
    "            v_results_L3 = [layers.Lambda(lambda x : tf.norm(x,ord = 1,axis=-1,keepdims=True))\n",
    "                (layers.subtract([\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('left_single_dimension_%s_size%s'%(gather,s1))]),\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('mid_single_dimension_%s_size%s'%(gather,s1))])\n",
    "            ])) for i in range(3)]\n",
    "            \n",
    "            v_results_L += v_results_L1\n",
    "            v_results_L += v_results_L2\n",
    "            v_results_L += v_results_L3\n",
    "            \n",
    "vertical_left_compared = layers.concatenate(v_results_L)\n",
    "\n",
    "del v_results_L\n",
    "del v_results_L1\n",
    "del v_results_L2\n",
    "del v_results_L3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertical comparison,AKA Algorithm 2 - cosine distance + L2 distance + L1 distance\n",
    "\n",
    "v_results_R = []\n",
    "for gather in ['avg','max','min']:\n",
    "    for num,s1 in enumerate(['2','3','Inf']): \n",
    "        for s2 in ['2','3','Inf'][num:]:\n",
    "        \n",
    "            \n",
    "            v_results_R.append(layers.dot([\n",
    "                    eval('right_size%s_%s'%(s1,gather)),eval('mid_size%s_%s'%(s2,gather))\n",
    "                ],axes = -1,normalize=True))\n",
    "            v_results_R.append(layers.Lambda(lambda x : tf.norm(x,ord = 2,axis=-1,keepdims=True))\n",
    "                         (layers.subtract([\n",
    "                    eval('right_size%s_%s'%(s1,gather)),eval('mid_size%s_%s'%(s2,gather))])))\n",
    "            v_results_R.append(layers.Lambda(lambda x : tf.norm(x,ord = 1,axis=-1,keepdims=True))\n",
    "                         (layers.subtract([\n",
    "                    eval('right_size%s_%s'%(s1,gather)),eval('mid_size%s_%s'%(s2,gather))])))    \n",
    "\n",
    "    if gather != 'avg':\n",
    "        for s1 in ['2','3']:    \n",
    "            \n",
    "            v_results_R1 = [layers.dot([\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('right_single_dimension_%s_size%s'%(gather,s1))]),\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('mid_single_dimension_%s_size%s'%(gather,s1))])\n",
    "            ],axes = -1,normalize=True) for i in range(3)]\n",
    "\n",
    "            v_results_R2 = [layers.Lambda(lambda x : tf.norm(x,ord = 2,axis=-1,keepdims=True))\n",
    "                (layers.subtract([\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('right_single_dimension_%s_size%s'%(gather,s1))]),\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('mid_single_dimension_%s_size%s'%(gather,s1))])\n",
    "            ])) for i in range(3)]\n",
    "\n",
    "            v_results_R3 = [layers.Lambda(lambda x : tf.norm(x,ord = 1,axis=-1,keepdims=True))\n",
    "                (layers.subtract([\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('right_single_dimension_%s_size%s'%(gather,s1))]),\n",
    "                layers.concatenate([(layers.Lambda(lambda x : K.reshape(x,[K.shape(x)[0],1])))\n",
    "                                (layers.Lambda(lambda x : x[:,i])(lay))\n",
    "                   for lay in eval('mid_single_dimension_%s_size%s'%(gather,s1))])\n",
    "            ])) for i in range(3)]\n",
    "            \n",
    "            v_results_R += v_results_R1\n",
    "            v_results_R += v_results_R2\n",
    "            v_results_R += v_results_R3\n",
    "            \n",
    "vertical_right_compared = layers.concatenate(v_results_R)\n",
    "\n",
    "del v_results_R\n",
    "del v_results_R1\n",
    "del v_results_R2\n",
    "del v_results_R3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dense layers at the top of network\n",
    "\n",
    "dens1 = layers.Dense(256,activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "droprout1 = layers.Dropout(0.5)\n",
    "\n",
    "\n",
    "merged_L = droprout1(dens1(layers.concatenate([horizontal_left_compared,vertical_left_compared])))\n",
    "merged_R = droprout1(dens1(layers.concatenate([horizontal_right_compared,vertical_left_compared])))\n",
    "\n",
    "\n",
    "dens2 = layers.Dense(256, activation='tanh',kernel_regularizer=regularizers.l2(1e-4))\n",
    "dens_pred = layers.Dense(1, activation=my_log_softmax,kernel_regularizer=regularizers.l2(1e-4))\n",
    "\n",
    "pred_L = dens_pred(dens2(merged_L))\n",
    "pred_R = dens_pred(dens2(merged_R))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred = layers.concatenate([pred_L,pred_R], axis = -1)\n",
    "\n",
    "model = Model(inputs = [left_input, mid_input, right_input], outputs = pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=triplet_loss, \n",
    "              optimizer=optimizers.Adam(lr=0.001,clipnorm=1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit({'n' : negative, 'q' : question, 'p' : positive},\n",
    "          np.zeros(len(negative)), #anything, basicly, not importent for loss function\n",
    "          epochs=10, \n",
    "          batch_size = 128,\n",
    "          verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
